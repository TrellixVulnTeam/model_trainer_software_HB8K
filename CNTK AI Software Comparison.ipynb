{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the library CNN built and used in each model training. We simply use the model's application below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading map file: data\\CIFAR-10\\train_map.txt\n",
      "Reading mean file: data\\CIFAR-10\\CIFAR-10_mean.xml\n",
      "Reading map file: data\\CIFAR-10\\test_map.txt\n",
      "Reading mean file: data\\CIFAR-10\\CIFAR-10_mean.xml\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import argparse\n",
    "import sys\n",
    "from CNN import create_reader,evaluate_model,train_and_evaluate,save_model,reader_train,reader_test,myimg\n",
    "\n",
    "\n",
    "try:\n",
    "    from urllib.request import urlopen\n",
    "except ImportError:\n",
    "    from urllib import urlopen\n",
    "\n",
    "import cntk as C\n",
    "\n",
    "if 'TEST_DEVICE' in os.environ:\n",
    "    if os.environ['TEST_DEVICE'] == 'cpu':\n",
    "        C.device.try_set_default_device(C.device.cpu())\n",
    "    else:\n",
    "        C.device.try_set_default_device(C.device.gpu(0))\n",
    "        \n",
    "model_name = \"test_simple_model.dnn\"\n",
    "data_path = os.path.join('data', 'CIFAR-10')\n",
    "import cntk.io.transforms as xforms\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_model(input, out_dims):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "        net = C.layers.Convolution((5,5), 32, pad=True)(input)\n",
    "        net = C.layers.MaxPooling((3,3), strides=(2,2))(net)\n",
    "\n",
    "        net = C.layers.Convolution((5,5), 32, pad=True)(net)\n",
    "        net = C.layers.MaxPooling((3,3), strides=(2,2))(net)\n",
    "\n",
    "        net = C.layers.Convolution((5,5), 64, pad=True)(net)\n",
    "        net = C.layers.MaxPooling((3,3), strides=(2,2))(net)\n",
    "\n",
    "        net = C.layers.Dense(64)(net)\n",
    "        net = C.layers.Dense(out_dims, activation=None)(net)\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"test_simple_model.dnn\"\n",
    "data_path = os.path.join('data', 'CIFAR-10')\n",
    "import cntk.io.transforms as xforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_simple_model(input, out_dims):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "        net = C.layers.Convolution((5,5), 32, pad=True)(input)\n",
    "        net = C.layers.MaxPooling((3,3), strides=(2,2))(net)\n",
    "\n",
    "        net = C.layers.Convolution((5,5), 32, pad=True)(net)\n",
    "        net = C.layers.MaxPooling((3,3), strides=(2,2))(net)\n",
    "\n",
    "        net = C.layers.Convolution((5,5), 64, pad=True)(net)\n",
    "        net = C.layers.MaxPooling((3,3), strides=(2,2))(net)\n",
    "\n",
    "        net = C.layers.Dense(64)(net)\n",
    "        net = C.layers.Dense(out_dims, activation=None)(net)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darli\\Anaconda3\\lib\\site-packages\\cntk\\learners\\__init__.py:340: RuntimeWarning: When providing the schedule as a number, epoch_size is ignored\n",
      "  warnings.warn('When providing the schedule as a number, epoch_size is ignored', RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 116906 parameters in 10 parameter tensors.\n",
      "\n",
      "Learning rate per 200 samples: 0.027\n",
      "Momentum per minibatch: 0.9\n",
      "Finished Epoch[1 of 10]: [Training] loss = 2.099899 * 50000, metric = 77.96% * 50000 48.495s (1031.0 samples/s);\n",
      "Finished Epoch[2 of 10]: [Training] loss = 1.736480 * 50000, metric = 64.28% * 50000 47.937s (1043.0 samples/s);\n"
     ]
    }
   ],
   "source": [
    "pred = train_and_evaluate(reader_train,\n",
    "                          reader_test,\n",
    "                          max_epochs=10,#was 1000\n",
    "                          model_func=create_simple_model,parX=0.027,parY=0.006,parZ=0.002,size_per_iter=250)\t\n",
    "evaluate_model(pred,myimg)\n",
    "save_model('pred_basic_model.dnn',pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_simple_sequential_model(input, out_dims):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "        model = C.layers.Sequential([\n",
    "            C.layers.For(range(3), lambda i: [\n",
    "                C.layers.Convolution((5,5), [32,32,64][i], pad=True),\n",
    "                C.layers.MaxPooling((3,3), strides=(2,2))\n",
    "                ]),\n",
    "            C.layers.Dense(64),\n",
    "            C.layers.Dense(out_dims, activation=None)\n",
    "        ])\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name=\"simple_sequntial_model.dnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_basic_model = train_and_evaluate(reader_train, \n",
    "                                      reader_test, \n",
    "                                      max_epochs=10, \n",
    "                                      model_func=create_simple_sequential_model,parX=0.025,parY=0.006,parZ=0.002,size_per_iter=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(pred_basic_model,myimg)\n",
    "save_model('simple_seq_model.dnn',pred_basic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dropout_model(input, out_dims):\n",
    "    with C.layers.default_options(activation=C.relu, init=C.glorot_uniform()):\n",
    "        model = C.layers.Sequential([\n",
    "            C.layers.For(range(3), lambda i: [\n",
    "                C.layers.Convolution((5,5), [32,32,64][i], pad=True),\n",
    "                C.layers.MaxPooling((3,3), strides=(2,2))\n",
    "            ]),\n",
    "            C.layers.Dense(64),\n",
    "            C.layers.Dropout(0.25),\n",
    "            C.layers.Dense(out_dims, activation=None)\n",
    "        ])\n",
    "    #print('Basic Model Prediction WITH DROPOUT')\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_basic_model_dropout = train_and_evaluate(reader_train, \n",
    "                                              reader_test, \n",
    "                                              max_epochs=5, \n",
    "                                              model_func=create_dropout_model,parX=0.01,parY=0.003,parZ=0.001,size_per_iter=250)\n",
    "evaluate_model(pred_basic_model_dropout,myimg)\n",
    "\n",
    "save_model('model_with_dropout.dnn',pred_basic_model_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_batch_normalized_model(input, out_dims):\n",
    "    with C.layers.default_options(activation=C.relu, init=C.glorot_uniform()):\n",
    "        model = C.layers.Sequential([\n",
    "            C.layers.For(range(3), lambda i: [\n",
    "                C.layers.Convolution((5,5), [32,32,64][i], pad=True),\n",
    "                C.layers.BatchNormalization(map_rank=1),\n",
    "                C.layers.MaxPooling((3,3), strides=(2,2))\n",
    "            ]),\n",
    "            C.layers.Dense(64),\n",
    "            C.layers.BatchNormalization(map_rank=1),\n",
    "            C.layers.Dense(out_dims, activation=None)\n",
    "        ])\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_basic_model_bn = train_and_evaluate(reader_train, reader_test, max_epochs=5, model_func=create_batch_normalized_model,parX=0.025,parY=0.006,parZ=0.002,size_per_iter=250)\n",
    "\n",
    "evaluate_model(pred_basic_model_bn,myimg)                              \n",
    "\n",
    "save_model('simple_bn_model.dnn',pred_basic_model_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_vgg_model(input, out_dims):\n",
    "    with C.layers.default_options(activation=C.relu, init=C.glorot_uniform()):\n",
    "        model = C.layers.Sequential([\n",
    "            C.layers.For(range(3), lambda i: [\n",
    "                C.layers.Convolution((3,3), [64,96,128][i], pad=True),\n",
    "                C.layers.Convolution((3,3), [64,96,128][i], pad=True),\n",
    "                C.layers.MaxPooling((3,3), strides=(2,2))\n",
    "            ]),\n",
    "            C.layers.For(range(2), lambda : [\n",
    "                C.layers.Dense(1024)\n",
    "            ]),\n",
    "            C.layers.Dense(out_dims, activation=None)\n",
    "        ])\n",
    "    #print('Basic Model Prediction WITH VGG9')\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_vgg = train_and_evaluate(reader_train, \n",
    "                              reader_test, \n",
    "                              max_epochs=5, \n",
    "                              model_func=create_vgg_model,parX=0.01,parY=0.003,parZ=0.001,size_per_iter=250)\n",
    "\t\t\t\t\t\t\t  \n",
    "evaluate_model(pred_vgg,myimg)\n",
    "\t\t\t\t\t\t\t  \n",
    "save_model('model_vgg.dnn',pred_vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution_bn(input, filter_size, num_filters, strides=(1,1), init=C.he_normal(), activation=C.relu):\n",
    "    if activation is None:\n",
    "        activation = lambda x: x\n",
    "    r = C.layers.Convolution(filter_size, \n",
    "                             num_filters, \n",
    "                             strides=strides, \n",
    "                             init=init, \n",
    "                             activation=None, \n",
    "                             pad=True, bias=False)(input)\n",
    "    r = C.layers.BatchNormalization(map_rank=1)(r)\n",
    "    r = activation(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet_basic(input, num_filters):\n",
    "    c1 = convolution_bn(input, (3,3), num_filters)\n",
    "    c2 = convolution_bn(c1, (3,3), num_filters, activation=None)\n",
    "    p  = c2 + input\n",
    "    return C.relu(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet_basic_inc(input, num_filters):\n",
    "    c1 = convolution_bn(input, (3,3), num_filters, strides=(2,2))\n",
    "    c2 = convolution_bn(c1, (3,3), num_filters, activation=None)\n",
    "\n",
    "    s = convolution_bn(input, (1,1), num_filters, strides=(2,2), activation=None)\n",
    "    \n",
    "    p = c2 + s\n",
    "    return C.relu(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet_basic_stack(input, num_filters, num_stack):\n",
    "    assert (num_stack > 0)\n",
    "    \n",
    "    r = input\n",
    "    for _ in range(num_stack):\n",
    "        r = resnet_basic(r, num_filters)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_resnet_model(input, out_dims):\n",
    "    conv = convolution_bn(input, (3,3), 16)\n",
    "    r1_1 = resnet_basic_stack(conv, 16, 3)\n",
    "\n",
    "    r2_1 = resnet_basic_inc(r1_1, 32)\n",
    "    r2_2 = resnet_basic_stack(r2_1, 32, 2)\n",
    "\n",
    "    r3_1 = resnet_basic_inc(r2_2, 64)\n",
    "    r3_2 = resnet_basic_stack(r3_1, 64, 2)\n",
    "\n",
    "    # Global average pooling\n",
    "    pool = C.layers.AveragePooling(filter_shape=(8,8), strides=(1,1))(r3_2)    \n",
    "    net = C.layers.Dense(out_dims, init=C.he_normal(), activation=None)(pool)\n",
    "    #print('Basic STACK Prediction WITH RESNET_MODEL')\n",
    "    return net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_resnet = train_and_evaluate(reader_train, reader_test, max_epochs=5, model_func=create_resnet_model,parX=0.02,parY=0.005,parZ=0.0018,size_per_iter=250)\n",
    "evaluate_model(pred_resnet,myimg)\n",
    "\n",
    "save_model('resilient_resnet_model.dnn',pred_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image(url=\"https://cntk.ai/jup/201/00014.png\", width=64, height=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
